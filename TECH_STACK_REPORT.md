# Tech Stack â€” Assistant vocal de chantier

## Rapport de comparaison & recommandation

*Mis Ã  jour pour intÃ©grer n8n comme couche orchestration backend.*

---

## 1. Contraintes techniques extraites du PRD

| # | Contrainte | PrioritÃ© | Ce qu'elle contraint |
|---|---|---|---|
| 1 | STT fiable en franÃ§ais, en milieu bruitÃ© | Critique | Moteur STT â€” choix nÂ°1 |
| 2 | Usage mobile (chantier, camion) | Critique | Frontend mobile-first |
| 3 | Relecture vocale par piÃ¨ce (TTS) | Critique | Moteur TTS |
| 4 | Auth email+mdp **ou** lien magique | Haute | SystÃ¨me d'authentification |
| 5 | Isolation stricte des donnÃ©es par organisation | Haute | Architecture multi-tenant |
| 6 | GÃ©nÃ©ration de document par piÃ¨ce | Haute | Couche gÃ©nÃ©ration document |
| 7 | DonnÃ©es relationnelles : org â†’ chantier â†’ piÃ¨ce â†’ ops | Moyenne | ModÃ¨le de donnÃ©es / BDD |
| 8 | Structuration par IA Ã  partir de V1 | Moyenne | LLM + structured output |
| 9 | Progression MVP â†’ V4 sans rewriting | Moyenne | Choix architecturaux |
| 10 | CoÃ»t raisonnable Ã  l'amorÃ§age | Basse | Free tiers, pricing |

**Observation critique sur iOS** :
Safari iOS ne supporte pas l'API `SpeechRecognition`. Le microphone via `getUserMedia()` fonctionne (Safari 16.4+, HTTPS),
mais la transcription **doit** Ãªtre faite server-side via une API externe.
Le Web Speech API natif du navigateur est donc **Ã©liminÃ©**.

---

## 2. Analyse par couche technologique

### 2.1 Speech-to-Text â€” Couche critique

C'est le choix qui fait ou casse le produit. Un STT qui Ã©choue en bruit = produit qui Ã©choue.

| CritÃ¨re | OpenAI Whisper | Google Cloud STT | Deepgram Nova | AWS Transcribe |
|---|---|---|---|---|
| QualitÃ© franÃ§ais | 5/5 | 5/5 | 4/5 | 3/5 |
| TolÃ©rance au bruit | 5/5 | 4/5 | 4/5 | 3/5 |
| Streaming temps rÃ©el | Non (batch) | Oui | Oui | Oui |
| Latence par chunk | ~2s | ~500ms | ~300ms | ~800ms |
| Prix / minute | $0.006 | $0.004 | ~$0.002 | $0.014 |
| Free tier | Non | 60 min/mois | 100h/mois | 60 min/mois |
| Node n8n natif | Non â†’ HTTP Request | Non â†’ HTTP Request | Non â†’ HTTP Request | Oui (AWS Transcribe) |

**Analyse** :
- **Whisper** domine sur la qualitÃ© brute et la robustesse au bruit pour du franÃ§ais.
  Le manque de streaming est un compromis acceptable (voir section 5).
- **Google Cloud STT** est le meilleur si on veut du streaming (mots en temps rÃ©el).
- Aucun des deux n'a de node n8n natif pour l'audio â€” tous deux passent par HTTP Request.
  C'est un niveau de complexitÃ© identique dans n8n.

---

### 2.2 Text-to-Speech

| CritÃ¨re | OpenAI TTS | Google Cloud TTS | ElevenLabs |
|---|---|---|---|
| NaturalitÃ© (franÃ§ais) | 4/5 | 4/5 | 5/5 |
| Latence gÃ©nÃ©ration | ~500ms | ~400ms | ~800ms |
| Prix / 1M caractÃ¨res | $15 | $4 | $300 |
| Node n8n natif | Non â†’ HTTP Request | Non â†’ HTTP Request | Non â†’ HTTP Request |

**Analyse** : OpenAI TTS et Google Cloud TTS sont suffisants. Aucun n'a de node n8n natif â€”
tous deux se font via HTTP Request. OpenAI reste cohÃ©rent avec Whisper (mÃªme clÃ© API).

---

### 2.3 Frontend / Plateforme mobile

Avec n8n comme backend, le frontend devient **UI uniquement** : pas de logique serveur, pas d'API routes.
Il fait deux choses : appeler les webhooks n8n (pour les traitements) et lire Supabase directement (pour l'affichage).

| CritÃ¨re | Next.js (PWA) | React Native (Expo) | Flutter |
|---|---|---|---|
| Vitesse dev MVP | 5/5 | 3.5/5 | 3/5 |
| ExpÃ©rience mobile | 3/5 | 5/5 | 5/5 |
| AccÃ¨s microphone iOS | Oui (HTTPS) | Natif | Natif |
| App Store requis | Non | Oui (V1+) | Oui (V1+) |
| Appel webhooks n8n | Fetch standard | Fetch standard | HTTP package |
| SDK Supabase disponible | Oui | Oui | LimitÃ© |

**Analyse** : Next.js PWA reste le meilleur choix pour un MVP rapide.
Le rÃ´le du frontend a simplifiÃ© : plus besoin d'API routes puisque n8n gÃ¨re l'orchestration.

---

### 2.4 n8n â€” Couche orchestration

C'est la couche qui remplace le backend custom. Voici ce qu'on a vÃ©rifiÃ© concrÃ¨tement sur les nodes disponibles :

| Besoin du projet | Node disponible | Limitation rÃ©elle |
|---|---|---|
| Recevoir un fichier audio | `Webhook` + option Binary Property | Max 16 MB â€” largement suffisant |
| Envoyer audio Ã  Whisper | `HTTP Request` (multipart-form-data) | Pas de node Whisper natif. Fonctionne via HTTP Request avec binary |
| Appeler GPT-4o | `OpenAI` node (ressource Chat) | Natif. Bon pour la structuration V1+ |
| GÃ©nÃ©rer du TTS | `HTTP Request` | Pas de node TTS natif. Retourne du binaire audio |
| Sauvegarder en Supabase | `Supabase` node | CRUD uniquement : create, get, get all, update, delete. Pas de SQL raw ni de JOINs |
| Lire des donnÃ©es Supabase | `Supabase` node (Get all rows) | Filtres simples par colonne. Pour des requÃªtes complexes â†’ HTTP Request vers l'API REST Supabase |
| Retourner du texte au frontend | `Respond to Webhook` | Oui, synchrone |
| Retourner du fichier audio au frontend | `Respond to Webhook` (First Entry Binary) | Oui, retourne du binaire |
| Convertir binary â†” JSON | `Convert to/from binary data` | Oui, utile pour manipuler l'audio dans le workflow |

**Ce que n8n fait bien pour ce projet :**
- ZÃ©ro code backend â€” les workflows sont visuels et modifiables sans dÃ©ploiement.
- DÃ©bogage visuel : on voit exactement oÃ¹ dans le pipeline quelque chose a Ã©chouÃ©.
- V1+ : les flows complexes (structuration, calcul prix, gÃ©nÃ©ration prÃ©-devis) sont naturels en n8n.
- Ajout d'intÃ©grations futures (Google Docs, notifications) sans toucher au code.

**Ce que n8n ne fait pas bien pour ce projet :**
- Pas de node Whisper ni TTS natif. Il faut configurer des HTTP Request avec du binaire â€” plus de configuration qu'un simple appel API en code.
- Le node Supabase est limitÃ© Ã  du CRUD. Les requÃªtes avec filtres multiples ou JOINs nÃ©cessitent des HTTP Request vers l'API REST Supabase.
- Chaque noeud du workflow ajoute ~100â€“200ms de latence. Le flow complet dictation (webhook â†’ Whisper â†’ Supabase â†’ rÃ©ponse) prend ~3s au total.
- Une instance n8n Ã  dÃ©ployer et maintenir en plus du frontend.

---

### 2.5 Base de donnÃ©es

Le modÃ¨le de donnÃ©es est **relationnel** : organisation â†’ chantier â†’ piÃ¨ce â†’ dimensions / opÃ©rations / observations.
Puis en V2 : bibliothÃ¨que d'opÃ©rations, prix, calculs.

| CritÃ¨re | Supabase | Firebase (Firestore) |
|---|---|---|
| Type de donnÃ©es | PostgreSQL (relationnel) | NoSQL (document) |
| DonnÃ©es relationnelles | Natif | Maladroit |
| Multi-tenant (isolation org) | Row Level Security | RÃ¨gles de sÃ©curitÃ© |
| Node n8n | Oui (CRUD) | Oui (Firestore) |
| SDK frontend disponible | Oui (supabase-js) | Oui (firebase) |
| Auth intÃ©grÃ©e | Oui (magic link + email) | Oui (magic link + email) |
| Free tier | TrÃ¨s bon | TrÃ¨s bon |
| Vendor lock-in | Faible (PostgreSQL standard) | Ã‰levÃ© (Firestore propriÃ©taire) |

**Analyse** : Supabase est le choix dominant. PostgreSQL pour les donnÃ©es relationnelles,
Row Level Security pour l'isolation par organisation, et l'auth magic link inclus.
Le node n8n Supabase est limitÃ© Ã  du CRUD mais c'est suffisant pour le MVP.

---

### 2.6 IA / LLM â€” Structuration et assistant

UtilisÃ© Ã  partir de V1 pour extraire des donnÃ©es structurÃ©es depuis les transcriptions.
Puis en V3 pour l'assistant mÃ©tier.

| CritÃ¨re | OpenAI GPT-4o | Anthropic Claude | Google Gemini |
|---|---|---|---|
| FranÃ§ais | 5/5 | 5/5 | 4/5 |
| Structured output (JSON) | JSON mode | Tool use | JSON mode |
| Prix input / 1M tokens | $2.50 | $3.00 | $1.25 |
| Prix output / 1M tokens | $10.00 | $15.00 | $5.00 |
| Node n8n natif | Oui (OpenAI Chat) | Oui (Anthropic) | Oui (Gemini) |
| CohÃ©rence avec Whisper/TTS | MÃªme fournisseur | Non | Non |

**Analyse** : GPT-4o avec le node OpenAI natif de n8n est le choix le plus simple.
C'est le seul moteur qui a Ã  la fois un node n8n natif **et** la cohÃ©rence avec Whisper + TTS
(mÃªme clÃ© API, mÃªme fournisseur). Le prix pour le volume attendu est nÃ©gligeable.

---

### 2.7 GÃ©nÃ©ration de documents

| Option | ComplexitÃ© | Format | OÃ¹ Ã§a se passe |
|---|---|---|---|
| HTML bien formatÃ© + print PDF | TrÃ¨s basse | HTML / PDF via navigateur | Frontend (Next.js) |
| PDF via react-pdf / jsPDF | Basse | PDF | Frontend |
| Google Docs API | Haute (OAuth) | Google Doc | n8n workflow (V1+) |

**Analyse** : Pour le MVP, un rendu HTML structurÃ© par piÃ¨ce exportable en PDF via le navigateur.
Simple, rapide, pas de dÃ©pendance externe. Google Docs API peut Ãªtre ajoutÃ© comme workflow n8n en V1+.

---

### 2.8 DÃ©ploiement

Deux services Ã  dÃ©ployer : le frontend et l'instance n8n.

| Service | Plateforme recommandÃ©e | CoÃ»t |
|---|---|---|
| Frontend (Next.js) | Vercel | Free tier |
| n8n | Railway (Docker) | ~$5â€“10/mois |
| Supabase | Supabase Cloud | Free tier |

---

## 3. Architecture recommandÃ©e

### 3.1 Vue globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“±  Next.js 15  â€”  PWA mobile                  â”‚
â”‚      UI uniquement                              â”‚
â”‚      Auth + lecture donnÃ©es : Supabase SDK      â”‚
â”‚      Traitements : appels webhooks vers n8n     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  POST webhooks    â”‚  Reads (direct SDK)
           â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”„  n8n        â”‚   â”‚  ğŸ—„ï¸  Supabase           â”‚
â”‚  (Railway)      â”‚   â”‚  Auth (magic link)      â”‚
â”‚                 â”‚   â”‚  PostgreSQL + RLS       â”‚
â”‚  Workflow 1 â”€â”€â”€â”€â”¼â”€â”€â–¶â”‚                         â”‚
â”‚  Dictation      â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                 â”‚
â”‚  Workflow 2     â”‚
â”‚  Relecture TTS  â”‚
â”‚                 â”‚
â”‚  Workflow 3     â”‚
â”‚  Correction     â”‚
â”‚                 â”‚
â”‚  Workflow 4+    â”‚
â”‚  Structuration  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚  HTTP calls
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¤–  OpenAI APIs                â”‚
â”‚  â€¢ Whisper  (via HTTP Request)  â”‚
â”‚  â€¢ TTS      (via HTTP Request)  â”‚
â”‚  â€¢ GPT-4o   (via OpenAI node)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Principe de sÃ©paration :**
- **Reads** (lister les chantiers, les piÃ¨ces, les transcriptions) : le frontend lit Supabase directement via le SDK. Rapide, pas de latence n8n.
- **Writes / Traitements** (envoyer de l'audio, corriger, structurer) : le frontend appelle un webhook n8n. n8n orchestre les appels API et la persistance.

---

### 3.2 Les workflows n8n en dÃ©tail

#### Workflow 1 : Dictation (MVP â€” couche critique)

```
Webhook (POST)
  â”œâ”€ Binary Property activÃ© â†’ reÃ§oit le fichier audio
  â”œâ”€ Body JSON â†’ reÃ§oit { piece_id, chantier_id, user_id }
  â””â”€ Respond : via 'Respond to Webhook' node

    â†“

HTTP Request â†’ api.openai.com/v1/audio/transcriptions
  â”œâ”€ Method : POST
  â”œâ”€ Content-Type : multipart/form-data
  â”œâ”€ Champs :
  â”‚     file  = binary audio du webhook
  â”‚     model = "whisper-1"
  â”‚     language = "fr"
  â””â”€ Auth : Bearer (clÃ© OpenAI)

    â†“  retourne { text: "..." }

Supabase node â†’ Create row
  â”œâ”€ Table : transcriptions
  â””â”€ Champs : piece_id, chantier_id, user_id, text, created_at

    â†“

Respond to Webhook
  â””â”€ Retourne : { text, piece_id, saved: true }
```

#### Workflow 2 : Relecture vocale par piÃ¨ce (MVP)

```
Webhook (POST)
  â””â”€ Body : { piece_id }

    â†“

Supabase node â†’ Get all rows
  â”œâ”€ Table : transcriptions
  â””â”€ Filtre : piece_id = valeur reÃ§ue
       (triÃ©es par created_at ASC)

    â†“

HTTP Request â†’ api.openai.com/v1/audio/speech
  â”œâ”€ Method : POST
  â”œâ”€ Body JSON : { model: "tts-1", input: texte assemblÃ©, voice: "alloy" }
  â”œâ”€ Auth : Bearer (clÃ© OpenAI)
  â””â”€ RÃ©ponse attendue : binaire (audio/mpeg)

    â†“

Respond to Webhook
  â””â”€ Response Data : First Entry Binary
       (retourne le fichier audio directement au navigateur)
```

#### Workflow 3 : Correction vocale (MVP)

```
Webhook (POST)
  â””â”€ Body : { piece_id, texte_correction }

    â†“

Supabase node â†’ Create row
  â”œâ”€ Table : corrections
  â””â”€ Champs : piece_id, texte, created_at

    â†“

Respond to Webhook
  â””â”€ Retourne : { success: true }
```

#### Workflow 4 : Structuration automatique (V1+)

```
Webhook (POST)
  â””â”€ Body : { chantier_id }

    â†“

Supabase node â†’ Get all rows
  â”œâ”€ Table : transcriptions
  â””â”€ Filtre : chantier_id = valeur reÃ§ue

    â†“

OpenAI node (Chat)
  â”œâ”€ ModÃ¨le : gpt-4o
  â”œâ”€ SystÃ¨me : prompt d'extraction structurÃ©e (piÃ¨ces, dimensions, opÃ©rations â†’ JSON)
  â””â”€ Utilisateur : toutes les transcriptions concatÃ©nÃ©es

    â†“  retourne JSON structurÃ©

Supabase node â†’ Create / Update rows
  â””â”€ Sauvegarde les donnÃ©es structurÃ©es

    â†“

Respond to Webhook
  â””â”€ Retourne : donnÃ©es structurÃ©es
```

#### Workflow 5 : Assistant mÃ©tier contextuel (V3)

```
Webhook (POST)
  â””â”€ Body : { question, contexte_chantier }

    â†“

OpenAI node (Chat)
  â”œâ”€ ModÃ¨le : gpt-4o
  â”œâ”€ SystÃ¨me : prompt assistant mÃ©tier (propose des options, ne dÃ©cide pas)
  â””â”€ Utilisateur : question + contexte

    â†“

Respond to Webhook
  â””â”€ Retourne : { options[], avertissement }
```

---

### 3.3 Configuration critique du Workflow 1 (audio binaire)

C'est le point le plus sensible de toute l'architecture.
Le fichier audio doit traverser trois Ã©tapes sans se corrompre :

```
1. Frontend enregistre l'audio via MediaRecorder  â†’  blob WebM ou MP3
2. Frontend envoie via fetch() en multipart/form-data vers le webhook n8n
3. Webhook reÃ§oit le binaire (option "Binary Property" activÃ©e, nom : "audio")
4. HTTP Request renvoie ce binaire Ã  Whisper en multipart/form-data
5. Whisper retourne la transcription en JSON
```

Points de configuration Ã  ne pas rater :
- Le Webhook doit avoir **Binary Property activÃ©** avec le nom du champ du formulaire multipart.
- Le HTTP Request vers Whisper doit Ãªtre en **multipart/form-data** avec le champ `file` qui rÃ©fÃ©rence le binaire du webhook.
- Le frontend doit envoyer l'audio comme un champ de formulaire multipart, pas comme un corps JSON.

---

## 4. CoÃ»t estimÃ©

### MVP (faible volume, quelques artisans en test)

| Service | Tier / usage | CoÃ»t/mois |
|---|---|---|
| Supabase | Free tier | $0 |
| Vercel (frontend) | Free tier | $0 |
| n8n | Self-hosted sur Railway (Starter) | ~$5â€“10 |
| OpenAI Whisper | ~30 min/mois de dictÃ©e | ~$0.20 |
| OpenAI TTS | ~500k caractÃ¨res/mois | ~$7.50 |
| OpenAI GPT-4o | ~100 requÃªtes/mois (V1+) | ~$0.50 |
| **Total estimÃ©** | | **~$13â€“18/mois** |

Ã€ noter : si vous hÃ©bergez n8n sur un serveur que vous possÃ©dez dÃ©jÃ  (Docker local ou VPS),
le coÃ»t n8n tombe Ã  $0 et le total reste < $10/mois.

---

## 5. Le compromis acceptÃ©

### Pas de streaming STT

Les mots n'apparaissent pas en temps rÃ©el â€” il y a un dÃ©lai de ~3 secondes aprÃ¨s chaque phrase
(~2s Whisper + ~1s overhead n8n). Ce compromis est justifiÃ© parce que :

- L'artisan dicte une phrase, fait une pause naturelle, puis continue.
  Le rythme "phrase â†’ pause â†’ phrase" est cohÃ©rent avec un traitement par chunks.
- Le PRD dit explicitement : *"Le MVP doit prouver l'usage rÃ©el, pas la performance technique."*
- Si les tests montrent que le dÃ©lai gÃªne, on remplace Whisper par Google Cloud STT streaming
  dans le mÃªme workflow n8n (mÃªme HTTP Request, autre URL, autre format de requÃªte).
  Le reste de l'architecture n'est pas touchÃ©.

### n8n vs code direct

Pour les flows du MVP (record â†’ STT â†’ afficher, et TTS playback), un simple backend en code
(quelques dizaines de lignes) serait plus rapide Ã  Ã©crire et plus rÃ©actif (moins de latence).
n8n ajoute une couche de configuration sur ces flows simples.

**Pourquoi accepter ce trade-off :** Ã  partir de V1, les flows deviennent complexes
(structuration multi-Ã©tapes, calculs, gÃ©nÃ©ration de documents). n8n vaut vraiment son prix lÃ .
Et les workflows MVP restent tels quels â€” on n'a rien Ã  reÃ©crire.

---

## 6. Feuille de route technique

### MVP

- Next.js 15 + Supabase (auth magic link + PostgreSQL)
- n8n self-hosted sur Railway
- **Workflow 1** : dictation audio â†’ Whisper â†’ Supabase â†’ rÃ©ponse
- **Workflow 2** : relecture TTS par piÃ¨ce
- **Workflow 3** : correction vocale simple
- Frontend : enregistrement audio, affichage par piÃ¨ce, export HTML/PDF
- DÃ©tection de commandes par mots-clÃ©s cÃ´tÃ© frontend : "relis", "corrige", "ajoute"

### V1 â€” Ajouts sur la mÃªme architecture

- **Workflow 4** : structuration automatique via GPT-4o
- Calcul des surfaces : logique mÃ©tier dans un noeud Code n8n ou cÃ´tÃ© frontend
- HÃ©ritage de contexte ("pareil que l'autre mur") : gÃ©rÃ© dans le prompt GPT-4o
- Marquage confirmÃ© / Ã  vÃ©rifier : champ en PostgreSQL

### V2

- BibliothÃ¨que d'opÃ©rations + prix : tables PostgreSQL
- Nouveau workflow n8n : calcul des montants (rÃ©cupÃ¨re surfaces + prix â†’ calcule â†’ retourne rÃ©sumÃ©)
- PrÃ©-devis exportable : mÃªme couche HTML/PDF cÃ´tÃ© frontend
- Pas de changement d'architecture

### V3

- **Workflow 5** : assistant mÃ©tier contextuel via GPT-4o
- DÃ©clenchement par mots-clÃ©s dÃ©tectÃ©s dans la transcription Whisper

### V4

- Workflow n8n pour la gÃ©nÃ©ration de devis via Google Docs API
- Historique des versions : dÃ©jÃ  supportÃ© par PostgreSQL
- Migration vers React Native possible sans toucher aux workflows n8n ni Ã  Supabase

---

## 7. Risques et mitigation

| Risque | ProbabilitÃ© | Impact | Mitigation |
|---|---|---|---|
| Le flow audio binaire ne marche pas dans n8n (webhook â†’ Whisper) | Moyenne | Critique | **C'est le premier truc Ã  tester**, avant tout le reste. Si Ã§a Ã©choue aprÃ¨s tests, on ajoute un thin proxy Node.js en entre pour gÃ©rer uniquement le binaire audio, et n8n rÃ©cupÃ¨re la transcription texte aprÃ¨s. |
| Whisper ne marche pas bien en bruit chantier rÃ©el | Moyenne | Critique | Tester avec des enregistrements rÃ©els. Si Ã§a Ã©choue, switcher vers Google Cloud STT dans le mÃªme workflow n8n. |
| Latence n8n trop Ã©levÃ©e (~3s par dictÃ©e) | Basse | Moyenne | Pour le MVP c'est acceptable. Si Ã§a devient bloquant en V1+, on peut externaliser le flow STT vers une API route rapide et garder n8n pour le reste. |
| Supabase node trop limitÃ© pour V1+ | Basse | Moyenne | Pour les requÃªtes complexes, on passe par HTTP Request vers l'API REST Supabase avec les bons query params. Le node Supabase reste pour le CRUD simple. |
| n8n outage (Railway down) | TrÃ¨s basse | Haute | Railway a une bonne SLA. En V1+, on peut ajouter un fallback. Pour le MVP, c'est un risque acceptable. |
| PWA pas fluide sur iOS | Basse | Haute | Tester sur un iPhone avant de valider le MVP. Si bloquant : migrer vers React Native â€” les workflows n8n et Supabase ne changent pas. |

---

## 8. Premier pas concret

```
1. CrÃ©er un compte Supabase (free tier)
2. DÃ©ployer une instance n8n sur Railway (Docker, image officielle n8n)
3. CrÃ©er un projet Next.js 15 sur Vercel

4. *** AVANT DE CODER AUTRE CHOSE *** :
   Construire le Workflow 1 (dictation) dans n8n :
       Webhook (binary) â†’ HTTP Request (Whisper) â†’ Respond to Webhook
   Tester avec un fichier audio rÃ©el depuis le navigateur.
       â†’ Si Ã§a marche : on continue.
       â†’ Si le binaire se corrompt : on teste avec un petit proxy Node.js en entre.
       â†’ Si Whisper Ã©choue en bruit : on teste Google Cloud STT Ã  la mÃªme place.

5. Une fois le Workflow 1 validÃ©, connecter Supabase (auth + premiÃ¨re table)
6. Construire le frontend : enregistrement audio â†’ appel webhook â†’ affichage
7. Construire le Workflow 2 (TTS) et tester la relecture
8. DÃ©ployer
```

**Le point 4 est le seul qui compte vraiment au dÃ©but.**
Deux risques en un : la gestion du binaire dans n8n, et la qualitÃ© de Whisper en bruit.
On les teste tous les deux en mÃªme temps, avec un seul workflow, avant de toucher Ã  quoi que ce soit d'autre.
